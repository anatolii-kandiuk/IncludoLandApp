"""
Progress Predictor ML service for game performance prediction.
"""
from typing import Dict, Optional, Tuple, Any
import logging
from pathlib import Path
import json

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
import joblib

from .data_extractor import extract_game_data, preprocess_features, extract_user_features

logger = logging.getLogger(__name__)


class ProgressPredictor:
    """
    Machine Learning model for predicting child's future game performance.
    
    Supports two model types:
    - 'linear': Linear Regression (faster, interpretable)
    - 'random_forest': Random Forest Regressor (more accurate, handles non-linearity)
    
    Features:
    - Training on historical game data
    - Predicting next score for specific user and game_type
    - Model persistence with joblib
    - Performance metrics tracking
    """
    
    FEATURE_COLUMNS = [
        'attempt_number',
        'avg_score',
        'std_score',
        'avg_duration',
        'total_hints',
        'score_trend',
        'last_score',
        'score_improvement',
        'days_since_start',
    ]
    
    def __init__(
        self,
        model_type: str = 'random_forest',
        model_dir: str = 'ml_models',
        window_size: int = 3,
    ):
        """
        Initialize the ProgressPredictor.
        
        Args:
            model_type: 'linear' or 'random_forest'
            model_dir: Directory to save/load models
            window_size: Number of past games to use for features
        """
        if model_type not in ['linear', 'random_forest']:
            raise ValueError("model_type must be 'linear' or 'random_forest'")
        
        self.model_type = model_type
        self.window_size = window_size
        self.model_dir = Path(model_dir)
        self.model_dir.mkdir(exist_ok=True)
        
        # Initialize model
        if model_type == 'linear':
            self.model = LinearRegression()
        else:
            self.model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42,
                n_jobs=-1,
            )
        
        # Feature scaler
        self.scaler = StandardScaler()
        
        # Training metrics
        self.metrics: Dict[str, float] = {}
        self.is_trained = False
        
        logger.info(
            f"Initialized ProgressPredictor with {model_type} model, "
            f"window_size={window_size}"
        )
    
    def train(
        self,
        game_type: Optional[str] = None,
        test_size: float = 0.2,
        min_entries: int = 5,
    ) -> Dict[str, float]:
        """
        Train the model on historical game data.
        
        Args:
            game_type: Specific game type to train on (None for all)
            test_size: Fraction of data to use for testing
            min_entries: Minimum entries per user-game combination
            
        Returns:
            Dictionary of performance metrics (MAE, RMSE, RÂ²)
            
        Raises:
            ValueError: If insufficient training data
        """
        try:
            logger.info(f"Starting training for game_type={game_type}")
            
            # Extract and preprocess data
            df = extract_game_data(
                user_id=None,
                game_type=game_type,
                min_entries=min_entries,
            )
            
            X, y = preprocess_features(df, window_size=self.window_size)
            
            # Encode game_type if present
            if 'game_type' in X.columns:
                # Simple hash encoding for game types
                X['game_type'] = X['game_type'].apply(lambda x: hash(x) % 10000)
            
            # Select only numeric features
            X_features = X[self.FEATURE_COLUMNS].copy()
            
            # Handle any missing values
            X_features = X_features.fillna(0)
            
            # Split data
            X_train, X_test, y_train, y_test = train_test_split(
                X_features,
                y,
                test_size=test_size,
                random_state=42,
            )
            
            logger.info(
                f"Training set: {len(X_train)} samples, "
                f"Test set: {len(X_test)} samples"
            )
            
            # Scale features
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)
            
            # Train model
            logger.info(f"Training {self.model_type} model...")
            self.model.fit(X_train_scaled, y_train)
            
            # Make predictions
            y_pred_train = self.model.predict(X_train_scaled)
            y_pred_test = self.model.predict(X_test_scaled)
            
            # Calculate metrics
            self.metrics = {
                'train_mae': mean_absolute_error(y_train, y_pred_train),
                'train_rmse': np.sqrt(mean_squared_error(y_train, y_pred_train)),
                'train_r2': r2_score(y_train, y_pred_train),
                'test_mae': mean_absolute_error(y_test, y_pred_test),
                'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),
                'test_r2': r2_score(y_test, y_pred_test),
                'n_samples': len(X),
                'n_features': X_features.shape[1],
            }
            
            self.is_trained = True
            
            logger.info(
                f"Training complete. Test MAE: {self.metrics['test_mae']:.2f}, "
                f"Test RMSE: {self.metrics['test_rmse']:.2f}, "
                f"Test RÂ²: {self.metrics['test_r2']:.3f}"
            )
            
            # Feature importance (for Random Forest)
            if self.model_type == 'random_forest':
                feature_importance = dict(zip(
                    self.FEATURE_COLUMNS,
                    self.model.feature_importances_
                ))
                logger.info(f"Feature importance: {feature_importance}")
            
            return self.metrics
            
        except Exception as e:
            logger.error(f"Error during training: {str(e)}")
            raise
    
    def predict(
        self,
        user_id: int,
        game_type: str,
    ) -> Optional[Dict[str, Any]]:
        """
        Predict next score and insights for a specific user and game type.
        
        Args:
            user_id: User ID
            game_type: Game type
            
        Returns:
            Dictionary with:
            - predicted_score: Predicted next score (0-100)
            - confidence: Confidence level (based on model performance)
            - insight: Human-readable insight string
            - days_to_mastery: Estimated days to reach mastery (score >= 90)
            - attempts_to_mastery: Estimated attempts to reach mastery
            
        Returns None if prediction cannot be made (insufficient data or untrained model)
        """
        if not self.is_trained:
            logger.warning("Model is not trained. Call train() first.")
            return None
        
        try:
            # Extract features for this user
            features = extract_user_features(
                user_id=user_id,
                game_type=game_type,
                window_size=self.window_size,
            )
            
            if features is None:
                return None
            
            # Prepare feature vector
            X_pred = pd.DataFrame([features])
            X_pred = X_pred[self.FEATURE_COLUMNS].fillna(0)
            
            # Scale features
            X_pred_scaled = self.scaler.transform(X_pred)
            
            # Make prediction
            predicted_score = float(self.model.predict(X_pred_scaled)[0])
            
            # Clip to valid score range
            predicted_score = np.clip(predicted_score, 0, 100)
            
            # Calculate confidence (inverse of test RMSE, normalized)
            confidence = max(0, min(100, 100 - self.metrics.get('test_rmse', 20)))
            
            # Generate insight
            insight = self._generate_insight(
                predicted_score=predicted_score,
                current_score=features['last_score'],
                score_trend=features['score_trend'],
                avg_score=features['avg_score'],
                game_type=game_type,
            )
            
            # Estimate mastery timeline
            mastery_threshold = 90
            days_to_mastery, attempts_to_mastery = self._estimate_mastery(
                current_score=features['last_score'],
                predicted_score=predicted_score,
                score_trend=features['score_trend'],
                days_since_start=features['days_since_start'],
                attempt_number=features['attempt_number'],
                mastery_threshold=mastery_threshold,
            )
            
            result = {
                'predicted_score': round(predicted_score, 1),
                'current_score': features['last_score'],
                'confidence': round(confidence, 1),
                'insight': insight,
                'days_to_mastery': days_to_mastery,
                'attempts_to_mastery': attempts_to_mastery,
                'score_trend': round(features['score_trend'], 2),
            }
            
            logger.info(
                f"Prediction for user {user_id}, game {game_type}: "
                f"score={predicted_score:.1f}, insight='{insight}'"
            )
            
            return result
            
        except Exception as e:
            logger.error(f"Error during prediction: {str(e)}")
            return None
    
    def _generate_insight(
        self,
        predicted_score: float,
        current_score: float,
        score_trend: float,
        avg_score: float,
        game_type: str,
    ) -> str:
        """Generate human-readable insight from prediction in Ukrainian."""
        
        # Game type labels in Ukrainian
        game_labels = {
            'math': 'Ð¼Ð°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸Ñ†Ñ–',
            'memory': 'Ñ–Ð³Ñ€Ð°Ñ… Ð½Ð° Ð¿Ð°Ð¼\'ÑÑ‚ÑŒ',
            'words': 'Ð¿Ð°Ð·Ð»Ð°Ñ… Ð·Ñ– ÑÐ»Ð¾Ð²Ð°Ð¼Ð¸',
            'sound': 'Ñ–Ð³Ñ€Ð°Ñ… Ð·Ñ– Ð·Ð²ÑƒÐºÐ°Ð¼Ð¸',
            'sentences': 'Ð¿Ð¾Ð±ÑƒÐ´Ð¾Ð²Ñ– Ñ€ÐµÑ‡ÐµÐ½ÑŒ',
            'articulation': 'Ð°Ñ€Ñ‚Ð¸ÐºÑƒÐ»ÑÑ†Ñ–Ð¹Ð½Ñ–Ð¹ Ð³Ñ–Ð¼Ð½Ð°ÑÑ‚Ð¸Ñ†Ñ–',
            'attention': 'Ñ–Ð³Ñ€Ð°Ñ… Ð½Ð° ÑƒÐ²Ð°Ð³Ñƒ',
        }
        game_label = game_labels.get(game_type, 'Ñ†Ñ–Ð¹ Ð³Ñ€Ñ–')
        
        score_diff = predicted_score - current_score
        
        # Determine skill level and advice
        if predicted_score >= 90:
            level_text = "Ð§ÑƒÐ´Ð¾Ð²Ð¸Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚! Ð”Ð¸Ñ‚Ð¸Ð½Ð° Ð´Ð¾ÑÑÐ³Ð»Ð° Ð¼Ð°Ð¹ÑÑ‚ÐµÑ€Ð½Ð¾ÑÑ‚Ñ–"
            if score_trend > 0.5:
                advice = f"ÐŸÑ€Ð¾Ð´Ð¾Ð²Ð¶ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÑƒÐ²Ð°Ñ‚Ð¸ Ñ–Ð½Ñ‚ÐµÑ€ÐµÑ Ð´Ð¾ {game_label}. ÐœÐ¾Ð¶Ð½Ð° Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð¸Ñ‚Ð¸ Ð´Ð¾ Ð±Ñ–Ð»ÑŒÑˆ ÑÐºÐ»Ð°Ð´Ð½Ð¸Ñ… Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ."
            else:
                advice = f"Ð’Ñ–Ð´Ð¼Ñ–Ð½Ð½Ð¸Ð¹ Ñ€Ñ–Ð²ÐµÐ½ÑŒ Ñƒ {game_label}! ÐœÐ¾Ð¶Ð½Ð° Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ²Ð°Ñ‚Ð¸ ÑÐº Ð¼Ð¾Ñ‚Ð¸Ð²Ð°Ñ†Ñ–ÑŽ Ð´Ð»Ñ Ñ–Ð½ÑˆÐ¸Ñ… Ð½Ð°Ð²Ð¸Ñ‡Ð¾Ðº."
        elif predicted_score >= 75:
            level_text = "Ð”ÑƒÐ¶Ðµ Ð´Ð¾Ð±Ñ€Ð¸Ð¹ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑ"
            if score_trend > 1.5:
                advice = f"Ð”Ð¸Ñ‚Ð¸Ð½Ð° Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÑƒÑ”Ñ‚ÑŒÑÑ Ð² {game_label}! Ð§ÐµÑ€ÐµÐ· ÐºÑ–Ð»ÑŒÐºÐ° Ð·Ð°Ð½ÑÑ‚ÑŒ Ð¼Ð¾Ð¶Ðµ Ð´Ð¾ÑÑÐ³Ñ‚Ð¸ Ð²Ñ–Ð´Ð¼Ñ–Ð½Ð½Ð¸Ñ… Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ–Ð²."
            elif score_trend > 0.5:
                advice = f"Ð¡Ñ‚Ð°Ð±Ñ–Ð»ÑŒÐ½Ðµ Ð·Ñ€Ð¾ÑÑ‚Ð°Ð½Ð½Ñ Ð² {game_label}. Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÑ”Ñ‚ÑŒÑÑ Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸ Ð² Ñ‚Ð°ÐºÐ¾Ð¼Ñƒ Ð¶ Ñ‚ÐµÐ¼Ð¿Ñ–."
            else:
                advice = f"Ð¥Ð¾Ñ€Ð¾ÑˆÐ¸Ð¹ Ñ€Ñ–Ð²ÐµÐ½ÑŒ Ñƒ {game_label}, Ð°Ð»Ðµ Ñ” Ð¼Ñ–ÑÑ†Ðµ Ð´Ð»Ñ Ñ€Ð¾ÑÑ‚Ñƒ. Ð”Ð¾Ð´Ð°Ð¹Ñ‚Ðµ Ð±Ñ–Ð»ÑŒÑˆÐµ Ð¿Ñ€Ð°ÐºÑ‚Ð¸ÐºÐ¸."
        elif predicted_score >= 60:
            level_text = "ÐŸÐ¾Ð¼Ñ–Ñ€Ð½Ð¸Ð¹ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑ"
            if score_trend > 1:
                advice = f"Ð”Ð¸Ñ‚Ð¸Ð½Ð° Ð½Ð°Ð¿Ñ€Ð°Ñ†ÑŒÐ¾Ð²ÑƒÑ” Ð½Ð°Ð²Ð¸Ñ‡ÐºÐ¸ Ð² {game_label}. ÐŸÑ–Ð´Ñ‚Ñ€Ð¸Ð¼ÑƒÐ¹Ñ‚Ðµ Ñ€ÐµÐ³ÑƒÐ»ÑÑ€Ð½Ñ–ÑÑ‚ÑŒ Ð·Ð°Ð½ÑÑ‚ÑŒ!"
            elif score_trend > 0:
                advice = f"ÐŸÐ¾Ð²Ñ–Ð»ÑŒÐ½Ðµ, Ð°Ð»Ðµ ÑÑ‚Ð°Ð±Ñ–Ð»ÑŒÐ½Ðµ Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½Ñ Ð² {game_label}. Ð’Ð°Ñ€Ñ‚Ð¾ Ñ‚Ñ€Ð¾Ñ…Ð¸ Ð·Ð±Ñ–Ð»ÑŒÑˆÐ¸Ñ‚Ð¸ Ñ‡Ð°Ñ Ð¿Ñ€Ð°ÐºÑ‚Ð¸ÐºÐ¸."
            else:
                advice = f"ÐÐ°Ð²Ð¸Ñ‡ÐºÐ¸ Ð² {game_label} Ð¿Ð¾Ñ‚Ñ€ÐµÐ±ÑƒÑŽÑ‚ÑŒ ÑƒÐ²Ð°Ð³Ð¸. Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÑ”Ñ‚ÑŒÑÑ Ð´Ð¾Ð´Ð°Ñ‚ÐºÐ¾Ð²Ð° Ð¿Ñ€Ð°ÐºÑ‚Ð¸ÐºÐ° Ñ‚Ð° Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÐºÐ°."
        else:
            level_text = "Ð Ð¾Ð·Ð²Ð¸Ñ‚Ð¾Ðº Ð½Ð°Ð²Ð¸Ñ‡Ð¾Ðº"
            if score_trend > 0.5:
                advice = f"Ð„ Ð¿Ð¾Ð·Ð¸Ñ‚Ð¸Ð²Ð½Ð° Ð´Ð¸Ð½Ð°Ð¼Ñ–ÐºÐ° Ð² {game_label}! ÐŸÑ€Ð¾Ð´Ð¾Ð²Ð¶ÑƒÐ¹Ñ‚Ðµ Ñ€Ð¾Ð±Ð¾Ñ‚Ñƒ, Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¸ Ð¾Ð±Ð¾Ð²'ÑÐ·ÐºÐ¾Ð²Ð¾ Ð¿Ð¾ÐºÑ€Ð°Ñ‰Ð°Ñ‚ÑŒÑÑ."
            elif score_trend >= 0:
                advice = f"Ð”Ð¸Ñ‚Ð¸Ð½Ð° Ð¿Ð¾Ñ‚Ñ€ÐµÐ±ÑƒÑ” Ð±Ñ–Ð»ÑŒÑˆÐµ ÑƒÐ²Ð°Ð³Ð¸ Ð´Ð¾ {game_label}. Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ–Ð½Ð´Ð¸Ð²Ñ–Ð´ÑƒÐ°Ð»ÑŒÐ½Ð¸Ð¹ Ð¿Ñ–Ð´Ñ…Ñ–Ð´ Ñ‚Ð° Ð´Ð¾Ð´Ð°Ñ‚ÐºÐ¾Ð²Ñƒ Ð¼Ð¾Ñ‚Ð¸Ð²Ð°Ñ†Ñ–ÑŽ."
            else:
                advice = f"Ð’Ð¸Ð½Ð¸ÐºÐ°ÑŽÑ‚ÑŒ Ñ‚Ñ€ÑƒÐ´Ð½Ð¾Ñ‰Ñ– Ð² {game_label}. Ð’Ð°Ñ€Ñ‚Ð¾ Ð¿ÐµÑ€ÐµÐ³Ð»ÑÐ½ÑƒÑ‚Ð¸ Ð¼ÐµÑ‚Ð¾Ð´Ð¸ÐºÑƒ Ñ‚Ð° Ð¿Ñ€Ð¸Ð´Ñ–Ð»Ð¸Ñ‚Ð¸ Ð±Ñ–Ð»ÑŒÑˆÐµ Ñ‡Ð°ÑÑƒ Ð±Ð°Ð·Ð¾Ð²Ð¸Ð¼ Ð²Ð¿Ñ€Ð°Ð²Ð°Ð¼."
        
        # Add emotional touch based on trend
        if score_trend > 2:
            emotion = "Ð‘Ð»Ð¸ÑÐºÑƒÑ‡Ð¸Ð¹ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑ! ðŸŒŸ"
        elif score_trend > 1:
            emotion = "Ð’Ñ–Ð´Ð¼Ñ–Ð½Ð½Ð° Ð´Ð¸Ð½Ð°Ð¼Ñ–ÐºÐ°! ðŸ“ˆ"
        elif score_trend > 0.3:
            emotion = "Ð„ Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½Ñ! âœ…"
        elif score_trend > -0.3:
            emotion = "Ð¡Ñ‚Ð°Ð±Ñ–Ð»ÑŒÐ½Ð¸Ð¹ Ñ€Ñ–Ð²ÐµÐ½ÑŒ ðŸ“Š"
        else:
            emotion = "ÐŸÐ¾Ñ‚Ñ€Ñ–Ð±Ð½Ð° ÑƒÐ²Ð°Ð³Ð° ðŸ’ª"
        
        return f"{emotion} {level_text}. {advice}"
    
    def _estimate_mastery(
        self,
        current_score: float,
        predicted_score: float,
        score_trend: float,
        days_since_start: float,
        attempt_number: float,
        mastery_threshold: float = 90,
    ) -> Tuple[Optional[int], Optional[int]]:
        """
        Estimate days and attempts needed to reach mastery.
        
        Returns:
            Tuple of (days_to_mastery, attempts_to_mastery)
            None values indicate already at mastery or trend is negative
        """
        if current_score >= mastery_threshold:
            return (0, 0)
        
        if score_trend <= 0.1:
            # Not improving, hard to estimate
            return (None, None)
        
        # Estimate attempts needed
        score_gap = mastery_threshold - current_score
        attempts_needed = int(np.ceil(score_gap / score_trend))
        
        # Estimate days needed (based on current pace)
        if attempt_number > 1 and days_since_start > 0:
            days_per_attempt = days_since_start / (attempt_number - 1)
            days_needed = int(np.ceil(attempts_needed * days_per_attempt))
        else:
            days_needed = None
        
        return (days_needed, attempts_needed)
    
    def save(self, game_type: Optional[str] = None) -> Path:
        """
        Save trained model and scaler to disk.
        
        Args:
            game_type: Game type identifier for filename (optional)
            
        Returns:
            Path to saved model file
            
        Raises:
            ValueError: If model is not trained
        """
        if not self.is_trained:
            raise ValueError("Cannot save untrained model")
        
        # Create filename
        game_suffix = f"_{game_type}" if game_type else "_all"
        model_file = self.model_dir / f"progress_predictor_{self.model_type}{game_suffix}.joblib"
        scaler_file = self.model_dir / f"scaler_{self.model_type}{game_suffix}.joblib"
        metrics_file = self.model_dir / f"metrics_{self.model_type}{game_suffix}.json"
        
        # Save model, scaler, and metrics
        joblib.dump(self.model, model_file)
        joblib.dump(self.scaler, scaler_file)
        
        with open(metrics_file, 'w') as f:
            json.dump(self.metrics, f, indent=2)
        
        logger.info(f"Model saved to {model_file}")
        
        return model_file
    
    def load(self, game_type: Optional[str] = None) -> bool:
        """
        Load trained model and scaler from disk.
        
        Args:
            game_type: Game type identifier for filename (optional)
            
        Returns:
            True if loaded successfully, False otherwise
        """
        try:
            # Create filename
            game_suffix = f"_{game_type}" if game_type else "_all"
            model_file = self.model_dir / f"progress_predictor_{self.model_type}{game_suffix}.joblib"
            scaler_file = self.model_dir / f"scaler_{self.model_type}{game_suffix}.joblib"
            metrics_file = self.model_dir / f"metrics_{self.model_type}{game_suffix}.json"
            
            if not model_file.exists():
                logger.warning(f"Model file not found: {model_file}")
                return False
            
            # Load model and scaler
            self.model = joblib.load(model_file)
            self.scaler = joblib.load(scaler_file)
            
            # Load metrics if available
            if metrics_file.exists():
                with open(metrics_file, 'r') as f:
                    self.metrics = json.load(f)
            
            self.is_trained = True
            logger.info(f"Model loaded from {model_file}")
            
            return True
            
        except Exception as e:
            logger.error(f"Error loading model: {str(e)}")
            return False
    
    def get_model_info(self) -> Dict[str, Any]:
        """
        Get information about the current model.
        
        Returns:
            Dictionary with model type, training status, and metrics
        """
        return {
            'model_type': self.model_type,
            'is_trained': self.is_trained,
            'window_size': self.window_size,
            'metrics': self.metrics,
            'feature_columns': self.FEATURE_COLUMNS,
        }
